{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POJ2scZv7vUZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Veri artırma için ImageDataGenerator**"
      ],
      "metadata": {
        "id": "zkFrFHMO8Mlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "cy2kkgFj8Utd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet Mimarisi**"
      ],
      "metadata": {
        "id": "Gv8j2zQP8XMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet50_model(input_shape, num_classes):\n",
        "    input_tensor = layers.Input(shape=input_shape)\n",
        "    x = layers.ZeroPadding2D(padding=(3, 3))(input_tensor)\n",
        "    x = layers.Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    output_tensor = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(input_tensor, output_tensor)\n",
        "    return model\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = layers.Conv2D(filters1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides, name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "b0FuruV_8bz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Veri işlemesi ve train-test ayrımı**"
      ],
      "metadata": {
        "id": "xU_6IfX38v27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/kaggle/input/crop-diseases-classification/Data/train_images'\n",
        "labels_csv_path = '/kaggle/input/crop-diseases-classification/Data/train.csv'\n",
        "\n",
        "labels_df = pd.read_csv(labels_csv_path)\n",
        "\n",
        "image_filenames = labels_df['image_id'].tolist()\n",
        "labels = labels_df['label'].tolist()\n",
        "\n",
        "image_paths = [os.path.join(data_dir, filename) for filename in image_filenames]\n",
        "\n",
        "valid_image_paths = []\n",
        "valid_labels = []\n",
        "\n",
        "for index, row in labels_df.iterrows():\n",
        "    image_path = os.path.join(data_dir, row['image_id'])\n",
        "    if os.path.exists(image_path):\n",
        "        valid_image_paths.append(image_path)\n",
        "        valid_labels.append(row['label'])\n",
        "\n",
        "\n",
        "if len(valid_image_paths) == 0:\n",
        "    raise ValueError(\"No valid image paths found. Please check your file paths and ensure the images exist.\")\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(valid_image_paths, valid_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "def preprocess_image(image_path, label, img_size=(224, 224)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, img_size)\n",
        "    image = image / 255.0  # Normalizasyon\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "3mwOkWW782Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Görüntü verilerini artırmak**"
      ],
      "metadata": {
        "id": "LTTEtVuq86HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "ubhwJZIY89y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Veri seti oluşturma ve ön işleme**"
      ],
      "metadata": {
        "id": "LxfAXkIs8_o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x, y: preprocess_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.map(lambda x, y: augment(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(lambda x, y: preprocess_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "  SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2b2E00ky9E1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Oluşturma ve Derleme**"
      ],
      "metadata": {
        "id": "Y4Lq5Z2a9HlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = len(set(valid_labels))\n",
        "\n",
        "model = resnet50_model(input_shape, num_classes)\n",
        "initial_learning_rate = 0.0001\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "for image_batch, label_batch in train_dataset.take(1):\n",
        "    print(f\"Image batch shape: {image_batch.shape}\")\n",
        "    print(f\"Label batch shape: {label_batch.shape}\")\n",
        "\n",
        "for image_batch, label_batch in test_dataset.take(1):\n",
        "    print(f\"Image batch shape: {image_batch.shape}\")\n",
        "    print(f\"Label batch shape: {label_batch.shape}\")"
      ],
      "metadata": {
        "id": "2P5fFv339Kro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Geri çağırma (callback)**"
      ],
      "metadata": {
        "id": "Y4MrSR3Q9PPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "0wlt9tVx9SXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modeli eğitme**"
      ],
      "metadata": {
        "id": "VOpSiAwE9U2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=30, validation_data=test_dataset, callbacks=[early_stopping, reduce_lr])"
      ],
      "metadata": {
        "id": "_69cs9Pc9XoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modeli test veri kümesi üzerinde değerlendirme**"
      ],
      "metadata": {
        "id": "0ZX9-HeX9g9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Loss grafiği\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy grafiği\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "LeR-d9Ln9kAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "y_pred = model.predict(test_dataset)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Gerçek etiketleri al\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "# Doğruluk (Accuracy)\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Kesinlik (Precision)\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "# Geri Çağırma (Recall)\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# F-ölçüsü (F1-Score)\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "60Ag1ZXT9vma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}